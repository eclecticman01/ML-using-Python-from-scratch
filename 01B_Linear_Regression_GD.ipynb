{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49ea78e0",
   "metadata": {},
   "source": [
    "### 01B. Linear Regression with Gradient Descent from Scratch using Python: Clarified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2957f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all packages\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import sympy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b317a",
   "metadata": {},
   "source": [
    "Generating example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bc04b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting random seed\n",
    "np.random.seed(42)\n",
    "\n",
    "#Generating age (x) and salaries (y)\n",
    "x = np.linspace(22,58,10) #Equally spaced 10 data points between age 22 and 58\n",
    "e = np.random.randn(10) #Random error term\n",
    "c = 20000 #Intercept I chose this randomly\n",
    "\n",
    "#Salary based on age of an employee. I chose the equation randomly\n",
    "y = 10000*x + c + e*80000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96a4977",
   "metadata": {},
   "source": [
    "Visualizing example dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba0637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot between x1 and y\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, color='blue', alpha=0.7)\n",
    "\n",
    "# plt.scatter(np.mean(x), np.mean(y), color='black', marker=\"h\",linewidths=10)\n",
    "plt.title('Salary vs Age')\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.ylabel('Salary (INR)')\n",
    "plt.ylim(bottom=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5f2997",
   "metadata": {},
   "source": [
    "### 1. Line Rotation Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64988cd1",
   "metadata": {},
   "source": [
    "a. Creating 10000 lines with different rotational angles and intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc90e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "#Calculate means\n",
    "xm = np.mean(x)\n",
    "ym = np.mean(y)\n",
    "\n",
    "# Scatter plot between x and y\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, color='blue', alpha=0.7)\n",
    "\n",
    "# Draw each line\n",
    "angles_deg = np.linspace(89.99,45,10000)\n",
    "angles_rad = np.deg2rad(angles_deg)\n",
    "intercepts = range(200000, 400000, 10000)\n",
    "rss = []\n",
    "slope = []\n",
    "inter = []\n",
    "\n",
    "i=1\n",
    "for a in angles_rad:\n",
    "    for b in intercepts:\n",
    "        m = np.tan(a)\n",
    "        c = b  #Equation to calculate c for the line which needs to be passed through center\n",
    "        y_rot = m*x + c #y values after 1 single rotation and intercept change\n",
    "        plt.plot(x, y_rot, color='red', linestyle=':')\n",
    "        rss_a = np.sum((y-y_rot)**2)\n",
    "        rss.append(rss_a)\n",
    "        slope.append(m)\n",
    "        inter.append(b)\n",
    "\n",
    "    i = i+1\n",
    "\n",
    "plt.title('Salary vs Age')\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.ylabel('Salary (INR)')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93111212",
   "metadata": {},
   "source": [
    "b. Calculating the best slope, intercept and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d801d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the minimum RSS\n",
    "min_rss = min(rss)\n",
    "\n",
    "#Get the slope corresponding to the minimum RSS\n",
    "pos = rss.index(min_rss)\n",
    "degree = angles_rad[0]\n",
    "best_slope = np.tan(degree)\n",
    "\n",
    "#Calculate the best intercept \n",
    "int = ym - best_slope*xm\n",
    "\n",
    "#Calculating prediction values\n",
    "y_best = best_slope*x + int\n",
    "\n",
    "print(f\"Min RSS: {min_rss},\\nBest Slope: {best_slope},\\nBest Intercept: {int}\")\n",
    "print(f\"Predictions: {y_best}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7a914",
   "metadata": {},
   "source": [
    "c. Visualizing RSS vs Slope from the line rotation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5745c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy arrays\n",
    "slopes = np.array(slope)\n",
    "intercepts = np.array(inter)\n",
    "rss_values = np.array(rss)\n",
    "\n",
    "# Determine shape of the mesh\n",
    "n_slope = len(set(slope))\n",
    "n_intercepts = len(set(inter))\n",
    "\n",
    "# Reshape for surface plot\n",
    "S = slopes.reshape((n_slope, n_intercepts))\n",
    "I = intercepts.reshape((n_slope, n_intercepts))\n",
    "R = rss_values.reshape((n_slope, n_intercepts))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "surf = ax.plot_surface(S, I, R, cmap='plasma')\n",
    "fig.colorbar(surf)\n",
    "\n",
    "ax.set_xlabel('Slope')\n",
    "ax.set_ylabel('Intercept')\n",
    "ax.set_zlabel('RSS')\n",
    "ax.set_title('RSS vs Slope and Intercept')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e804f5",
   "metadata": {},
   "source": [
    "### 2. Calculating Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8536a3",
   "metadata": {},
   "source": [
    "a. Calculating Gradient Descent for a generic univariate equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f4516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbolic variables\n",
    "m, c = sp.symbols('m c')\n",
    "x_i, y_i = sp.symbols('x_i y_i')\n",
    "\n",
    "# RSS for a single data point (i-th)\n",
    "RSS_i = (y_i - (m*x_i + c))**2\n",
    "\n",
    "# Partial derivatives\n",
    "dRSS_dm = sp.diff(RSS_i, m)\n",
    "dRSS_dc = sp.diff(RSS_i, c)\n",
    "\n",
    "print(\"Partial derivative w.r.t m:\")\n",
    "sp.pprint(dRSS_dm)\n",
    "\n",
    "print(\"\\nPartial derivative w.r.t c:\")\n",
    "sp.pprint(dRSS_dc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f671d",
   "metadata": {},
   "source": [
    "b. Calculating Gradient Descent for my Salary vs Age equation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de8791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define symbolic variables for parameters only\n",
    "m, c = sp.symbols('m c')\n",
    "x_i, y_i = sp.symbols('x_i y_i')\n",
    "\n",
    "# RSS for a single data point\n",
    "RSS_i = (y_i - (m*x_i + c))**2\n",
    "\n",
    "# Partial derivatives for one point\n",
    "dRSS_dm_i = sp.diff(RSS_i, m)\n",
    "dRSS_dc_i = sp.diff(RSS_i, c)\n",
    "\n",
    "# Initialize symbolic sums (start at 0)\n",
    "grad_m_sum = 0\n",
    "grad_c_sum = 0\n",
    "\n",
    "# Sum partial derivatives over all data points with numeric xi, yi plugged in. x and y are coming from the top cell where I have defined the salary vs age data.\n",
    "for xi, yi in zip(x, y):\n",
    "    grad_m_sum = grad_m_sum + dRSS_dm_i.subs({x_i: xi, y_i: yi})\n",
    "    grad_c_sum = grad_c_sum + dRSS_dc_i.subs({x_i: xi, y_i: yi})\n",
    "\n",
    "# Display the symbolic expressions for the total gradients\n",
    "print(\"Gradient w.r.t m:\")\n",
    "print(grad_m_sum)\n",
    "\n",
    "print(\"\\nGradient w.r.t c:\")\n",
    "print(grad_c_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6632ccce",
   "metadata": {},
   "source": [
    "c. Testing the above gradient equation with dummy values (0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fce0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substitute values of m and c after the loop\n",
    "mi = 0.0\n",
    "ci = 0.0\n",
    "\n",
    "result_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "result_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "print(f\"Evaluated gradient at m={mi}, c={ci}:\")\n",
    "print(f\"dRSS/dm = {result_m}\")\n",
    "print(f\"dRSS/dc = {result_c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494d07c",
   "metadata": {},
   "source": [
    "d. using the gradient equation, creating a loop to iterate over multiple m and c values with a fixed learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2628c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Manual\n",
    "eta = 0.01\n",
    "\n",
    "#Iteration 1\n",
    "mi=0\n",
    "ci=0\n",
    "\n",
    "grad_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "grad_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "print(grad_m)\n",
    "print(grad_c)\n",
    "\n",
    "#Iteration 2\n",
    "\n",
    "m_old = mi\n",
    "c_old = ci\n",
    "\n",
    "mnew = m_old-(eta*grad_m)\n",
    "cnew = c_old-(eta*grad_c)\n",
    "\n",
    "print(\"m_new: \",mnew)\n",
    "print(\"c_new: \",cnew)\n",
    "\n",
    "mi = mnew\n",
    "ci = cnew\n",
    "\n",
    "grad_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "grad_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "print(grad_m)\n",
    "print(grad_c)\n",
    "\n",
    "#Iteration 3\n",
    "\n",
    "m_old = mi\n",
    "c_old = ci\n",
    "\n",
    "mnew = m_old-(eta*grad_m)\n",
    "cnew = c_old-(eta*grad_c)\n",
    "\n",
    "print(\"m_new: \",mnew)\n",
    "print(\"c_new: \",cnew)\n",
    "\n",
    "mi = mnew\n",
    "ci = cnew\n",
    "\n",
    "grad_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "grad_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "print(grad_m)\n",
    "print(grad_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919ac340",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "eta = 0.00005 #Leraning rate\n",
    "mi=5000 #Initial m and c\n",
    "ci=50000\n",
    "n_iterations = 1000 #Iterations\n",
    "\n",
    "for i in range(100000):\n",
    "    grad_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "    grad_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "    m_old = mi\n",
    "    c_old = ci\n",
    "\n",
    "    mnew = m_old-(eta*grad_m)\n",
    "    cnew = c_old-(eta*grad_c)\n",
    "\n",
    "    mi = mnew\n",
    "    ci = cnew\n",
    "\n",
    "    grad_m = grad_m_sum.subs({m: mi, c: ci}).evalf()\n",
    "    grad_c = grad_c_sum.subs({m: mi, c: ci}).evalf()\n",
    "\n",
    "    \n",
    "    i = i+1\n",
    "    print(f\"Iteration: \",i, \"Values of m and c:\", mi, ci, \"Gradients at {mi} and {ci}:\", grad_m, grad_c)\n",
    "\n",
    "    if (abs(grad_m) < abs(0.001)) & (abs(grad_c) < abs(0.001)):\n",
    "        break\n",
    "\n",
    "print(f\"Final parameter values for m: {mi} and c: {ci}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea095b1",
   "metadata": {},
   "source": [
    "e. Visualizing results from OLS and GD methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da189b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#OLS parameters\n",
    "\n",
    "m_o = 9861.99256632237\n",
    "c_o = 61365.18628300569\n",
    "y_o = m_o*x + c_o\n",
    "\n",
    "#GD parameters\n",
    "\n",
    "m_gd = 9861.99256632237\n",
    "c_gd = 61365.18628300569\n",
    "y_gd = m_gd*x + c_gd\n",
    "\n",
    "# Scatter plot between x and y\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(x, y, color='blue', alpha=0.7)\n",
    "plt.plot(x, y_o, color='orange', linestyle=\"-\",label='OLS Method')\n",
    "plt.plot(x, y_gd, color='red', linestyle=\"-\",label='GD Method')\n",
    "\n",
    "plt.title('Salary vs Age')\n",
    "plt.xlabel('Age (Years)')\n",
    "plt.ylabel('Salary (INR)')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a462d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading California housing dataset\n",
    "data = datasets.fetch_california_housing()\n",
    "\n",
    "#Getting a pandas dataframe\n",
    "df = pd.DataFrame(data['data'])\n",
    "df['target'] = data['target']\n",
    "df.columns = data['feature_names']+data['target_names']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7784a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the x and y (regressors/features and target value)\n",
    "x = np.array(df.drop('MedHouseVal',axis=1))\n",
    "y = np.array(df['MedHouseVal'])\n",
    "\n",
    "#Adding intercept to features\n",
    "X = np.c_[np.ones((x.shape[0], 1)),x]\n",
    "\n",
    "#Let me start will all beta with 0\n",
    "beta = np.zeros(X.shape[1])\n",
    "\n",
    "# Hyperparameters\n",
    "eta = 0.00000000001 \n",
    "n_iterations = 100000\n",
    "\n",
    "for i in range(n_iterations):\n",
    "    grad = -2 * X.T.dot(y - X.dot(beta))\n",
    "    beta_new = beta - eta * grad\n",
    "    print(f\"Iteration: \",i, \"Values of beta:\", beta, \"Gradients at beta:\", grad)\n",
    "    if np.all(np.abs(grad) < 0.001):\n",
    "        break\n",
    "    else:\n",
    "        beta = beta_new\n",
    "    \n",
    "print(f\"Final parameter values for beta: {beta_new}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
